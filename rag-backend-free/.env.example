# Application Configuration
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
TOP_K_RESULTS=5

# Local LLM Configuration (Ollama)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b

# Local Embedding Model
EMBEDDING_MODEL=all-MiniLM-L6-v2

# ChromaDB Configuration (local)
CHROMA_PERSIST_DIRECTORY=./chroma_db

# CORS Configuration
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:8000

# NO API KEYS NEEDED - COMPLETELY FREE!
